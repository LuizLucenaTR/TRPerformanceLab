name: Performance Tests (Load & Stress)

# Add permissions for GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

on:
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of performance test to run'
        required: true
        type: choice
        options:
          - load
          - stress
        default: 'load'
      target_endpoint:
        description: 'Base URL of the API to test (e.g., https://api.example.com)'
        required: true
        type: string
      v_users:
        description: 'Number of Virtual Users (VUs) / Concurrency'
        required: true
        type: number
        default: 10
      test_duration:
        description: 'Duration of the test (e.g., 5m, 30s)'
        required: true
        type: string
        default: '5m'
      ramp_up_time:
        description: 'Time to reach max VUs (e.g., 1m)'
        required: true
        type: string
        default: '1m'
      rps_rate:
        description: 'Requests Per Second rate (optional)'
        required: false
        type: number
      auth_type:
        description: 'Authentication type'
        required: true
        type: choice
        options:
          - none
          - basic_auth
          - bearer_token
        default: 'none'

jobs:
  run_performance_test:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup k6
        run: |
          # Download k6 binary directly (more reliable than GPG method)
          curl -L https://github.com/grafana/k6/releases/download/v0.47.0/k6-v0.47.0-linux-amd64.tar.gz | tar xvz --strip-components 1
          sudo mv k6 /usr/local/bin/
          chmod +x /usr/local/bin/k6
          echo "📦 k6 installed successfully:"
          k6 version
          echo "🔧 Available k6 options:"
          k6 run --help | head -20 || echo "Help not available"
          
      - name: Create results directory
        run: |
          mkdir -p test-results
          echo "📁 Results directory created: $(pwd)/test-results"
          ls -la test-results/
          
      - name: Debug Test Configuration
        run: |
          echo "🔍 Test Configuration Debug:"
          echo "Test Type: '${{ github.event.inputs.test_type }}'"
          echo "Target Endpoint: '${{ github.event.inputs.target_endpoint }}'"
          echo "Virtual Users: '${{ github.event.inputs.v_users }}'"
          echo "Test Duration: '${{ github.event.inputs.test_duration }}'"
          echo "Auth Type: '${{ github.event.inputs.auth_type }}'"
          echo ""
          echo "Condition evaluation:"
          echo "test_type == 'load': ${{ github.event.inputs.test_type == 'load' }}"
          echo "test_type == 'stress': ${{ github.event.inputs.test_type == 'stress' }}"
          
      - name: Run Load Test
        if: ${{ github.event.inputs.test_type == 'load' }}
        continue-on-error: true
        env:
          TARGET_ENDPOINT: ${{ github.event.inputs.target_endpoint }}
          V_USERS: ${{ github.event.inputs.v_users }}
          TEST_DURATION: ${{ github.event.inputs.test_duration }}
          RAMP_UP_TIME: ${{ github.event.inputs.ramp_up_time }}
          RPS_RATE: ${{ github.event.inputs.rps_rate }}
          AUTH_TYPE: ${{ github.event.inputs.auth_type }}
          BASIC_AUTH_USER: ${{ vars.BASIC_AUTH_USER }}
          BASIC_AUTH_PASS: ${{ vars.BASIC_AUTH_PASS }}
          BEARER_TOKEN: ${{ vars.BEARER_TOKEN }}
        run: |
          echo "🚀 Starting Load Test with detailed logging..."
          echo "Target: $TARGET_ENDPOINT | VUsers: $V_USERS | Duration: $TEST_DURATION | Auth: $AUTH_TYPE"
          
          # Test network connectivity first
          echo "🌐 TESTANDO CONECTIVIDADE DE REDE:"
          echo "Target: $TARGET_ENDPOINT"
          
          # Extract domain from URL
          DOMAIN=$(echo $TARGET_ENDPOINT | sed -E 's|https?://([^/]+).*|\1|')
          echo "Domain: $DOMAIN"
          
          # Test DNS resolution
          echo "🔍 DNS Resolution test:"
          nslookup $DOMAIN || echo "❌ DNS resolution failed"
          
          # Test ping (may not work due to ICMP blocking, but worth trying)
          echo "🏓 Ping test (3 packets):"
          ping -c 3 $DOMAIN || echo "❌ Ping failed (normal for many servers)"
          
          # Test HTTPS connection with curl
          echo "🔗 HTTPS Connection test:"
          timeout 30 curl -v --connect-timeout 10 --max-time 30 -I "$TARGET_ENDPOINT" || echo "❌ HTTPS connection failed"
          
          echo "========================================"
          
          # Print the exact command that will be executed
          echo "📝 COMANDO K6 EXATO QUE SERÁ EXECUTADO:"
          echo "k6 run --out json=test-results/load-test-results.json tests/performance/load_test_scenario.js"
          echo "📝 VARIÁVEIS DE AMBIENTE:"
          echo "  - TARGET_ENDPOINT=$TARGET_ENDPOINT"
          echo "  - V_USERS=$V_USERS"
          echo "  - TEST_DURATION=$TEST_DURATION"
          echo "  - RAMP_UP_TIME=$RAMP_UP_TIME"
          echo "  - AUTH_TYPE=$AUTH_TYPE"
          echo "  - BASIC_AUTH_USER=$BASIC_AUTH_USER"
          echo "  - BASIC_AUTH_PASS=$BASIC_AUTH_PASS"
          echo "  - BEARER_TOKEN=$BEARER_TOKEN"
          echo "========================================"
          
          # Run k6 with JSON output and continue on threshold failures
          echo "🚀 Executing k6 load test..."
          k6 run --out json=test-results/load-test-results.json \
                 tests/performance/load_test_scenario.js 2>&1 | tee test-results/k6-load-test.log || true
          
          echo "✅ Load Test completed (check logs for details)"
          
          # Verify and display results
          echo "📂 Checking test results directory:"
          ls -la test-results/ || echo "❌ test-results directory not found"
          
          # Display basic results summary
          if [ -f test-results/load-test-results.json ]; then
            echo "📊 Test Results Generated:"
            echo "- JSON: test-results/load-test-results.json ($(wc -l < test-results/load-test-results.json) lines)"
            echo "- Log: test-results/k6-load-test.log"
          else
            echo "❌ JSON results file not created, creating placeholder..."
            echo '{"error": "k6 execution failed", "timestamp": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'"}' > test-results/load-test-results.json
          fi
          
          # Ensure log file exists
          if [ ! -f test-results/k6-load-test.log ]; then
            echo "❌ Log file not created, creating placeholder..."
            echo "Load test execution failed - no k6 log generated" > test-results/k6-load-test.log
          fi
          
      - name: Run Stress Test
        if: ${{ github.event.inputs.test_type == 'stress' }}
        continue-on-error: true
        env:
          TARGET_ENDPOINT: ${{ github.event.inputs.target_endpoint }}
          V_USERS: ${{ github.event.inputs.v_users }}
          TEST_DURATION: ${{ github.event.inputs.test_duration }}
          RAMP_UP_TIME: ${{ github.event.inputs.ramp_up_time }}
          RPS_RATE: ${{ github.event.inputs.rps_rate }}
          AUTH_TYPE: ${{ github.event.inputs.auth_type }}
          BASIC_AUTH_USER: ${{ vars.BASIC_AUTH_USER }}
          BASIC_AUTH_PASS: ${{ vars.BASIC_AUTH_PASS }}
          BEARER_TOKEN: ${{ vars.BEARER_TOKEN }}
        run: |
          echo "🚀 Starting Stress Test with detailed logging..."
          echo "Target: $TARGET_ENDPOINT | VUsers: $V_USERS | Duration: $TEST_DURATION | Auth: $AUTH_TYPE"
          
          # Test network connectivity first
          echo "🌐 TESTANDO CONECTIVIDADE DE REDE:"
          echo "Target: $TARGET_ENDPOINT"
          
          # Extract domain from URL
          DOMAIN=$(echo $TARGET_ENDPOINT | sed -E 's|https?://([^/]+).*|\1|')
          echo "Domain: $DOMAIN"
          
          # Test DNS resolution
          echo "🔍 DNS Resolution test:"
          nslookup $DOMAIN || echo "❌ DNS resolution failed"
          
          # Test ping (may not work due to ICMP blocking, but worth trying)
          echo "🏓 Ping test (3 packets):"
          ping -c 3 $DOMAIN || echo "❌ Ping failed (normal for many servers)"
          
          # Test HTTPS connection with curl
          echo "🔗 HTTPS Connection test:"
          timeout 30 curl -v --connect-timeout 10 --max-time 30 -I "$TARGET_ENDPOINT" || echo "❌ HTTPS connection failed"
          
          echo "========================================"
          
          # Print the exact command that will be executed
          echo "📝 COMANDO K6 EXATO QUE SERÁ EXECUTADO:"
          echo "k6 run --out json=test-results/stress-test-results.json tests/performance/stress_test_scenario.js"
          echo "📝 VARIÁVEIS DE AMBIENTE:"
          echo "  - TARGET_ENDPOINT=$TARGET_ENDPOINT"
          echo "  - V_USERS=$V_USERS"
          echo "  - TEST_DURATION=$TEST_DURATION"
          echo "  - RAMP_UP_TIME=$RAMP_UP_TIME"
          echo "  - AUTH_TYPE=$AUTH_TYPE"
          echo "  - BASIC_AUTH_USER=$BASIC_AUTH_USER"
          echo "  - BASIC_AUTH_PASS=$BASIC_AUTH_PASS"
          echo "  - BEARER_TOKEN=$BEARER_TOKEN"
          echo "========================================"
          
          # Run k6 with JSON output and continue on threshold failures
          echo "🚀 Executing k6 stress test..."
          k6 run --out json=test-results/stress-test-results.json \
                 tests/performance/stress_test_scenario.js 2>&1 | tee test-results/k6-stress-test.log || true
          
          echo "✅ Stress Test completed (check logs for details)"
          
          # Verify and display results
          echo "📂 Checking test results directory:"
          ls -la test-results/ || echo "❌ test-results directory not found"
          
          # Display basic results summary
          if [ -f test-results/stress-test-results.json ]; then
            echo "📊 Test Results Generated:"
            echo "- JSON: test-results/stress-test-results.json ($(wc -l < test-results/stress-test-results.json) lines)"
            echo "- Log: test-results/k6-stress-test.log"
          else
            echo "❌ JSON results file not created, creating placeholder..."
            echo '{"error": "k6 execution failed", "timestamp": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'"}' > test-results/stress-test-results.json
          fi
          
          # Ensure log file exists
          if [ ! -f test-results/k6-stress-test.log ]; then
            echo "❌ Log file not created, creating placeholder..."
            echo "Stress test execution failed - no k6 log generated" > test-results/k6-stress-test.log
          fi
          
      - name: Display Detailed Test Logs
        if: always()
        run: |
          echo "🔍 Analyzing Test Results and Logs..."
          echo "============================================"
          
          # Show k6 log files if they exist
          if [ -f test-results/k6-load-test.log ]; then
            echo "📋 Load Test Log (last 50 lines):"
            echo "-----------------------------------"
            tail -n 50 test-results/k6-load-test.log
            echo ""
          fi
          
          if [ -f test-results/k6-stress-test.log ]; then
            echo "📋 Stress Test Log (last 50 lines):"
            echo "------------------------------------"
            tail -n 50 test-results/k6-stress-test.log
            echo ""
          fi
          
          # Extract and display HTTP status codes from JSON results
          if [ -f test-results/load-test-results.json ]; then
            echo "📊 Load Test HTTP Status Codes:"
            echo "-------------------------------"
            grep '"http_req_failed"' test-results/load-test-results.json | head -10 || echo "No HTTP failure data found"
            echo ""
          fi
          
          if [ -f test-results/stress-test-results.json ]; then
            echo "📊 Stress Test HTTP Status Codes:"
            echo "---------------------------------"
            grep '"http_req_failed"' test-results/stress-test-results.json | head -10 || echo "No HTTP failure data found"
            echo ""
          fi
          
          echo "✅ Detailed analysis completed"
          
      - name: Prepare artifacts for upload
        if: always()
        run: |
          echo "🗂️ Preparing artifacts for upload..."
          echo "Current directory: $(pwd)"
          echo "test-results contents:"
          ls -la test-results/ || echo "test-results directory not found"
          
          # Ensure test-results directory exists with some content
          mkdir -p test-results
          
          # Create summary file
          echo "Performance Test Execution Summary" > test-results/test-summary.txt
          echo "=====================================" >> test-results/test-summary.txt
          echo "Test Type: ${{ github.event.inputs.test_type }}" >> test-results/test-summary.txt
          echo "Target: ${{ github.event.inputs.target_endpoint }}" >> test-results/test-summary.txt
          echo "VUsers: ${{ github.event.inputs.v_users }}" >> test-results/test-summary.txt
          echo "Duration: ${{ github.event.inputs.test_duration }}" >> test-results/test-summary.txt
          echo "Timestamp: $(date -u)" >> test-results/test-summary.txt
          echo "GitHub Run: ${{ github.run_id }}" >> test-results/test-summary.txt
          
          # Ensure at least basic files exist
          [ ! -f test-results/${{ github.event.inputs.test_type }}-test-results.json ] && echo '{"status": "no results generated"}' > test-results/${{ github.event.inputs.test_type }}-test-results.json
          [ ! -f test-results/k6-${{ github.event.inputs.test_type }}-test.log ] && echo "No k6 log generated for ${{ github.event.inputs.test_type }} test" > test-results/k6-${{ github.event.inputs.test_type }}-test.log
          
          echo "Final test-results contents:"
          ls -la test-results/
          
      - name: Upload test results as artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-test-results-${{ github.event.inputs.test_type }}
          path: test-results/
          retention-days: 30
          if-no-files-found: warn
          
      - name: Set up Java for Allure
        if: always()
        uses: actions/setup-java@v4
        with:
          java-version: '11'
          distribution: 'temurin'
          
      - name: Install Allure CLI
        if: always()
        run: |
          curl -o allure-2.24.0.tgz -L https://github.com/allure-framework/allure2/releases/download/2.24.0/allure-2.24.0.tgz
          sudo tar -zxf allure-2.24.0.tgz -C /opt/
          sudo ln -s /opt/allure-2.24.0/bin/allure /usr/bin/allure
          allure --version
          
      - name: Generate Allure Report
        if: always()
        run: |
          echo "📊 Generating Allure Report..."
          
          # Create directories
          mkdir -p allure-results
          mkdir -p allure-report
          
          # Install Node.js for JSON processing (if not available)
          node --version || (curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash - && sudo apt-get install -y nodejs)
          
          # Create k6 to Allure converter
          cat > convert-k6-to-allure.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          
          function generateUuid() {
            return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
              const r = Math.random() * 16 | 0;
              const v = c == 'x' ? r : (r & 0x3 | 0x8);
              return v.toString(16);
            });
          }
          
          function convertK6ToAllure(k6JsonPath, allureResultsDir) {
            console.log(`Converting ${k6JsonPath} to Allure format...`);
            
            if (!fs.existsSync(k6JsonPath)) {
              console.log(`K6 results file not found: ${k6JsonPath}`);
              return;
            }
            
            const k6Data = fs.readFileSync(k6JsonPath, 'utf8');
            const lines = k6Data.split('\n').filter(line => line.trim());
            
            let testResults = {
              name: `${{ github.event.inputs.test_type }} Performance Test`,
              status: 'passed',
              start: Date.now() - 300000, // 5 minutes ago
              stop: Date.now(),
              uuid: generateUuid(),
              historyId: generateUuid(),
              fullName: `${{ github.event.inputs.test_type }}_performance_test`,
              labels: [
                { name: 'suite', value: 'Performance Tests' },
                { name: 'testClass', value: '${{ github.event.inputs.test_type }}' },
                { name: 'testMethod', value: 'execute' },
                { name: 'package', value: 'k6.performance' },
                { name: 'framework', value: 'k6' },
                { name: 'language', value: 'javascript' }
              ],
              links: [
                { name: 'Repository', url: '${{ github.server_url }}/${{ github.repository }}' }
              ],
              steps: [],
              attachments: []
            };
            
            let httpReqDurations = [];
            let httpReqFailed = 0;
            let httpReqCount = 0;
            let vus = 0;
            
            lines.forEach(line => {
              try {
                const data = JSON.parse(line);
                
                if (data.type === 'Point' && data.metric) {
                  switch (data.metric) {
                    case 'http_req_duration':
                      httpReqDurations.push(data.data.value);
                      break;
                    case 'http_req_failed':
                      if (data.data.value > 0) httpReqFailed++;
                      break;
                    case 'http_reqs':
                      httpReqCount++;
                      break;
                    case 'vus':
                      vus = Math.max(vus, data.data.value);
                      break;
                  }
                }
              } catch (e) {
                // Skip invalid JSON lines
              }
            });
            
            // Calculate statistics
            const avgDuration = httpReqDurations.length > 0 ? 
              httpReqDurations.reduce((a, b) => a + b, 0) / httpReqDurations.length : 0;
            const maxDuration = httpReqDurations.length > 0 ? Math.max(...httpReqDurations) : 0;
            const minDuration = httpReqDurations.length > 0 ? Math.min(...httpReqDurations) : 0;
            const failureRate = httpReqCount > 0 ? (httpReqFailed / httpReqCount) * 100 : 0;
            
            // Determine test status
            testResults.status = failureRate > ('${{ github.event.inputs.test_type }}' === 'stress' ? 30 : 10) ? 'failed' : 'passed';
            testResults.statusDetails = {
              message: `${{ github.event.inputs.test_type }} test completed with ${failureRate.toFixed(2)}% failure rate`,
              trace: `Target: ${{ github.event.inputs.target_endpoint }}\nRequests: ${httpReqCount}\nFailed: ${httpReqFailed}\nAvg Duration: ${avgDuration.toFixed(2)}ms\nMax VUs: ${vus}`
            };
            
            // Add detailed steps
            testResults.steps.push({
              name: 'Performance Test Execution',
              status: testResults.status,
              start: testResults.start,
              stop: testResults.stop,
              parameters: [
                { name: 'Test Type', value: '${{ github.event.inputs.test_type }}' },
                { name: 'Target Endpoint', value: '${{ github.event.inputs.target_endpoint }}' },
                { name: 'Virtual Users', value: '${{ github.event.inputs.v_users }}' },
                { name: 'Test Duration', value: '${{ github.event.inputs.test_duration }}' },
                { name: 'Total Requests', value: httpReqCount.toString() },
                { name: 'Failed Requests', value: httpReqFailed.toString() },
                { name: 'Failure Rate', value: `${failureRate.toFixed(2)}%` },
                { name: 'Avg Response Time', value: `${avgDuration.toFixed(2)}ms` },
                { name: 'Min Response Time', value: `${minDuration.toFixed(2)}ms` },
                { name: 'Max Response Time', value: `${maxDuration.toFixed(2)}ms` },
                { name: 'Max Virtual Users', value: vus.toString() }
              ]
            });
            
            // Write Allure result file
            const resultFile = path.join(allureResultsDir, `${testResults.uuid}-result.json`);
            fs.writeFileSync(resultFile, JSON.stringify(testResults, null, 2));
            
            console.log(`✅ Generated Allure result: ${resultFile}`);
            console.log(`📊 Test Status: ${testResults.status}`);
            console.log(`📈 Failure Rate: ${failureRate.toFixed(2)}%`);
            return testResults;
          }
          
          // Process k6 results
          const resultsPath = 'test-results';
          const allureResultsDir = 'allure-results';
          
          // Process the specific test type results
          const testType = '${{ github.event.inputs.test_type }}';
          const k6ResultFile = `${resultsPath}/${testType}-test-results.json`;
          
          if (fs.existsSync(k6ResultFile)) {
            convertK6ToAllure(k6ResultFile, allureResultsDir);
          } else {
            console.log(`⚠️  K6 result file not found: ${k6ResultFile}`);
            // Create a basic failed test result
            const failedResult = {
              name: `${testType} Performance Test`,
              status: 'broken',
              start: Date.now() - 60000,
              stop: Date.now(),
              uuid: generateUuid(),
              statusDetails: {
                message: 'Test execution failed - no results file generated',
                trace: 'Check the k6 execution logs for more details'
              }
            };
            fs.writeFileSync(`${allureResultsDir}/${failedResult.uuid}-result.json`, JSON.stringify(failedResult, null, 2));
          }
          EOF
          
          # Run the converter
          node convert-k6-to-allure.js
          
          # Create environment file for Allure
          cat > allure-results/environment.properties << EOF
          Test.Type=${{ github.event.inputs.test_type }}
          Target.Endpoint=${{ github.event.inputs.target_endpoint }}
          Virtual.Users=${{ github.event.inputs.v_users }}
          Test.Duration=${{ github.event.inputs.test_duration }}
          Authentication=${{ github.event.inputs.auth_type }}
          Execution.Time=$(date -u +"%Y-%m-%d %H:%M:%S UTC")
          GitHub.Run.ID=${{ github.run_id }}
          GitHub.Repository=${{ github.repository }}
          GitHub.Actor=${{ github.actor }}
          GitHub.Workflow=${{ github.workflow }}
          EOF
          
          # Generate the Allure report
          echo "🔄 Generating Allure HTML report..."
          allure generate allure-results -o allure-report --clean
          
          echo "✅ Allure report generated successfully"
          
      - name: Setup GitHub Pages
        if: always()
        uses: actions/configure-pages@v4
        
      - name: Upload Allure Report as Pages artifact
        if: always()
        uses: actions/upload-pages-artifact@v3
        with:
          path: allure-report
          
      - name: Deploy to GitHub Pages
        if: always()
        id: deployment
        uses: actions/deploy-pages@v4
          
      - name: Display Test Summary
        if: always()
        run: |
          echo "## Performance Test Results 🚀" >> $GITHUB_STEP_SUMMARY
          echo "**Test Type:** ${{ github.event.inputs.test_type }}" >> $GITHUB_STEP_SUMMARY
          echo "**Target Endpoint:** ${{ github.event.inputs.target_endpoint }}" >> $GITHUB_STEP_SUMMARY
          echo "**Virtual Users:** ${{ github.event.inputs.v_users }}" >> $GITHUB_STEP_SUMMARY
          echo "**Test Duration:** ${{ github.event.inputs.test_duration }}" >> $GITHUB_STEP_SUMMARY
          echo "**Ramp Up Time:** ${{ github.event.inputs.ramp_up_time }}" >> $GITHUB_STEP_SUMMARY
          echo "**Authentication:** ${{ github.event.inputs.auth_type }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Add test result status
          if [ -f test-results/${{ github.event.inputs.test_type }}-test-results.json ]; then
            echo "**Test Status:** ✅ Completed (results generated)" >> $GITHUB_STEP_SUMMARY
            echo "**Logs Available:** Yes (check artifacts)" >> $GITHUB_STEP_SUMMARY
          else
            echo "**Test Status:** ⚠️ Issues detected (check logs)" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "📊 **Allure Report:** ${{ steps.deployment.outputs.page_url || format('https://{0}.github.io/{1}/', github.repository_owner, github.event.repository.name) }}" >> $GITHUB_STEP_SUMMARY
          echo "📋 **Detailed Logs:** Available in artifacts section" >> $GITHUB_STEP_SUMMARY
          echo "🔗 **GitHub Pages Deploy:** ${{ steps.deployment.outputs.page_url && 'Successful' || 'Check Pages settings' }}" >> $GITHUB_STEP_SUMMARY
